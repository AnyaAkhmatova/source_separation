# Epoch hyperparams
stabilization_epochs: 1.0
pruning_epochs: 6.0
quantization_epochs: 3.0
freeze_bn: 2.0

# Learning rate hyperparams
init_lr: 1e-4
final_lr: 5e-5

# Pruning hyperparams
init_sparsity: 0.05
final_sparsity: 0.3

# Stabalization Stage
training_modifiers:
  - !EpochRangeModifier
    start_epoch: 0.0
    end_epoch: eval(stabilization_epochs + pruning_epochs + quantization_epochs)
  
  - !SetLearningRateModifier
    start_epoch: 0.0
    learning_rate: eval(init_lr)

# Pruning Stage
pruning_modifiers:
  - !LearningRateFunctionModifier
    init_lr: eval(init_lr)
    final_lr: eval(final_lr)
    lr_func: cosine
    start_epoch: eval(stabilization_epochs)
    end_epoch: eval(stabilization_epochs + pruning_epochs)
    
  - !GlobalMagnitudePruningModifier
    init_sparsity: eval(init_sparsity)
    final_sparsity: eval(final_sparsity)
    start_epoch: eval(stabilization_epochs)
    end_epoch: eval(stabilization_epochs + pruning_epochs)
    update_frequency: 0.5
    params: __ALL_PRUNABLE__
    leave_enabled: True

# Quantization Stage
quantization_modifiers:
  - !QuantizationModifier
      start_epoch: eval(stabilization_epochs + pruning_epochs)
      freeze_bn_stats_epoch: eval(stabilization_epochs + pruning_epochs + freeze_bn)

  - !SetLearningRateModifier
      start_epoch: eval(stabilization_epochs + pruning_epochs)
      learning_rate: 1e-5
