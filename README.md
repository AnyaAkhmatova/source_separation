# Свёрточные нейросетевые модели для разделения аудио в сеттинге аудиопотока

## Исследовательский проект, весна 2024

В этом репозитории находится код для обучения сверточных нейронных сетей для разделения смесей аудио на компоненты в стриминговом сеттинге. Код был написан и использован в ходе работы над исследовательским проектом.

Нашей целью было получить хорошее решение для задачи целевого разделения аудио на компоненты в онлайн режиме. Модель должна была быть с хорошим качеством, небольшим количеством параметров и быстрым инференсом. Мы остановились на сверточных нейронных сетях. За основу мы взяли state-of-the-art архитектуру для офлайн режима - SpexPlus (https://arxiv.org/pdf/2005.04686), это адаптация Conv-TasNet (https://arxiv.org/pdf/1809.07454v3) к задаче целевого разделения. Мы переделали ее под онлайн формат, добавили работу с последовательными сегментами аудио. Затем мы разработали для архитектуры множество механизмов памяти для увеличения захватываемого контекста во время последовательной обработки сегментов аудио-миксов, чтобы улучшить ее качество. Предложенные модификации были протестированы в ходе экспериментов. Мы выбрали наилучший механизм памяти, давший наилучшие значения метрик, и продолжили работу с ним. Далее мы попытались уменьшить размеры имеющегося решения. Сначала мы попытались применить к архитектуре структурные изменения, варьируя ее гиперпараметры. В ходе экспериментов удалось получить сжатое решение с улучшенными значениями метрик, меньшим весом и большей скоростью инференса. Затем мы попытались применить к получившейся сети стандартные техники сжатия размеров моделей - прунинг и квантизацию, надеясь улучшить результат. В этой части работы мы не смогли провести эксперименты в достаточном количестве из-за лимитов в ресурсах и времени. Проведенные эксперименты не дали улучшений показателей модели. Они улучшили скорость инференса, но не за счет прунинга или квантизации, а из-за экпорта модели в формат onnx с оптимизированными вычислениями. На этом наша работа закончилась, мы получили пару моделей с неплохим качеством, довольно легких и быстрых. Подробнее об исследовании можно прочитать в отчете.

____

### Устройство репозитория

Репозиторий устроен следующим образом: 

- ss - основной пакет с классами и функциями для обучения, тестирования и инференса моделей, включает в себя:
    - datasets - код для работы с данными (есть две версии Dataloader с DistributedSampler и без него)
    - metric - классы для подсчета метрик (ACC, SNR, SISDR, CompositeMetric\PESQ, STOI)
    - model - модуль с имплементациями архитектур (бейзлайны: SpexPlus, SpexPlusShort, модели с памятью: SpexPlusShortRNN, SpexPlusShortGRUModel(versions 0-3), SpexPlusShortCacheModel, SpexPlusShortSpecialChannelsModel, модели для прунинга и квантизации: SpexPlusShortSpeakerHandler, SpexPlusShortGRUMainModel)
    - loss - код для подсчета функции потерь (SpexPlusLoss для обычных моделей и SpexPlusShortLoss для short моделей)
    - streamer - код для класса, разбивающего аудио на сегменты для обработки (есть режимы half с пересечением на половину и nonintersec без пересечений, во всех экспериментах использовали half)
    - trainer - имплементации классов для обучения моделей (Trainer - для офлайн режима, CausalTrainer - для онлайн режима, ShortCausalTrainer - для short моделей в онлайн формате, SimpleShortCausalTrainer - для работы с speaker_handler и main_model, прунинга и квантизации main_model, все классы запускают обучение для DistributedDataParallel моделей)
    - inferencer - имплементации классов для инференса моделей (Inferencer - для офлайн режима, CausalInferencer - для онлайн режима, ShortCausalInferencer - для short моделей в онлайн формате, все классы запускают инференс для DistributedDataParallel моделей)
    - utils - вспомогательные функции и классы
    - wandb - логгер в wandb

- training - директория с кодом для запуска обучения (train - в офлайн режиме, causal_train - в онлайн режиме, short_causal_train - для short моделей в онлайн формате, во всех версиях распределенное обучение), конфигурации для обучения лежат в поддиректории configs (пример можно найти там)

- testing - директория с кодом для запуска тестирования (test - в офлайн режиме, causal_test - в онлайн режиме, short_causal_test - для short моделей в онлайн формате, во всех версиях распределенное тестирование), конфигурации для тестирования лежат в поддиректории configs (пример можно найти там)

- inferencing - директория с кодом для запуска инференса (inference - в офлайн режиме, causal_inference - в онлайн режиме, short_causal_inference - для short моделей в онлайн формате, во всех версиях распределенный инференс), конфигурации для инференса лежат в поддиректории configs (пример можно найти там)

- mixing - код для создания набора данных, миксов аудиозаписей, конфигурации лежат в поддиректории configs (пример можно найти там)

- measure_weight_and_time - код для замера количества параметров, macs и скорости обработки данных модели, конфигурации лежат в поддиректории configs (пример можно найти там)

- pruning_and_quantization - код для прунинга и/или квантизации моделей (prune_and_quantize запускает обучение DistributedDataParallel модели и сохраняет ее в конце в форматах pth и onnx, test запускает тест onnx-моделей на GPU, inference запускает инференс onnx-моделей на GPU, measure_weight_and_time делает замеры количества параметров и скорости инференса у моделей на GPU или CPU), конфигурации лежат в поддиректории configs (примеры можно найти там), рецепты для прунинга/квантизации лежат в поддиректории recipes (примеры можно найти там)

____

### Среда для работы

Чтобы начать работу с кодом необходимо установить все необходимые библиотеки и пакеты.

Если нет задачи проводить прунинг/квантизацию, необходимо выполнить следующие команды внутри директории репозитория:

```
pip install -r ./requirements.txt
pip install .
```

Если планируется проведение прунинга/квантизации, необходимо выполнить следующие команды внутри директории репозитория:

```
pip install -r ./requirements_new.txt
pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/
pip install onnx
pip install .
```

Далее следует авторизоваться в wandb:

```
wandb login
```
____

### Запуски обучения, тестирования, инференса и т.п.

Необходимо должным образом настроить конфигурации (см. примеры) и сделать запуск. Например: 

```
# для обучения
python3 ./training/short_causal_train.py -cp ./configs/ -cn spexplusshort_gru
# для тестирования
python3 ./testing/short_causal_test.py -cp ./configs/ -cn spexplusshort_gru
# для инференса
python3 ./inferencing/short_causal_inference.py -cp ./configs/ -cn spexplusshort_gru
# и т.п.
```

____

Более подробно с ходом и результатами исследования можно ознакомиться в финальном отчете.

Ход проведенных экспериментов можно посмотреть в отчете на wandb, ссылка: https://wandb.ai/crazy_ocean_ahead/online_target_source_separation/reports/---Vmlldzo3OTY1Njk0.

Веса моделей так же выложены в открытый доступ, ссылка: https://drive.google.com/drive/folders/1TaJE2PC0XJImqLEQKp8uqDw8AEqWHp2P.

Ссылка на сгенерированный нами и используемый в работе набор данных: https://www.kaggle.com/datasets/girleygirl/otss-dataset.


